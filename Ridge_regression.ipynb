{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6uk7kAzNdVCE80NbHvC69",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ehtisham1053/Regression-ML-Algorithms/blob/main/Ridge_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook I will code about the ridge regression using the both CLosed form and Gradient Descent technique"
      ],
      "metadata": {
        "id": "0ezepDTk5rhA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KzT2vEdG5oW9"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
        "from  sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"audi.csv\")\n",
        "df.isnull().sum().sum() # no  null value\n",
        "\n",
        "x = df.drop(\"price\",axis=1)\n",
        "y = df[\"price\"]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n",
        "\n",
        "\n",
        "c = ColumnTransformer(transformers = [\n",
        "    (\"cat\" , OneHotEncoder(handle_unknown='ignore' , sparse_output=False , drop='first') , ['model' ,'transmission', 'fuelType']),\n",
        "    (\"num\" , StandardScaler() , ['year' , 'mileage' , 'mpg' , 'engineSize', 'tax'])\n",
        "] ,\n",
        "                      remainder = \"passthrough\")\n",
        "\n",
        "\n",
        "x_train = c.fit_transform(x_train)\n",
        "x_test = c.transform(x_test)"
      ],
      "metadata": {
        "id": "xfBfvQll580G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.to_numpy()\n",
        "y_test = y_test.to_numpy()"
      ],
      "metadata": {
        "id": "cEVFt1166HZ_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ridge regression using the closed form solution"
      ],
      "metadata": {
        "id": "eZbIS6ah62CB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RidgeRegressionClosedForm:\n",
        "    def __init__(self, alpha=1.0):\n",
        "        self.alpha = alpha  # Regularization strength\n",
        "        self.m = None  # Coefficients\n",
        "        self.b = None  # Intercept\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        X_bias = np.c_[np.ones((n_samples, 1)), X]  # Adding bias term\n",
        "        I = np.eye(n_features + 1)\n",
        "        I[0, 0] = 0  # No regularization for bias term\n",
        "\n",
        "        self.theta = np.linalg.inv(X_bias.T @ X_bias + self.alpha * I) @ X_bias.T @ y\n",
        "        self.b = self.theta[0]\n",
        "        self.m = self.theta[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.m) + self.b\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        y_pred = self.predict(X_test)\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        return {\"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}"
      ],
      "metadata": {
        "id": "ORYWEXVN6LaF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_closed = RidgeRegressionClosedForm(alpha=1.0)\n",
        "ridge_closed.fit(x_train, y_train)\n",
        "print(\"Closed-Form Metrics:\", ridge_closed.evaluate(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFzfJH1D6l0w",
        "outputId": "d736a955-97c5-4b29-ec19-0d1e984298a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closed-Form Metrics: {'MSE': 15151108.707749944, 'RMSE': 3892.4425118105396, 'R2': 0.8897427711385432}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation using the gradient descent"
      ],
      "metadata": {
        "id": "UjjHrUPX8B86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RidgeRegressionGradientDescent:\n",
        "    def __init__(self, alpha=1.0, learning_rate=0.01, epochs=1000):\n",
        "        self.alpha = alpha  # Regularization strength\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.m = None  # Coefficients\n",
        "        self.b = None  # Intercept\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.m = np.zeros(n_features)\n",
        "        self.b = 0\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "            y_pred = np.dot(X, self.m) + self.b\n",
        "            error = y_pred - y\n",
        "\n",
        "            grad_m = (1 / n_samples) * (np.dot(X.T, error) + self.alpha * self.m)  # Regularized gradient\n",
        "            grad_b = (1 / n_samples) * np.sum(error)\n",
        "\n",
        "            self.m -= self.learning_rate * grad_m\n",
        "            self.b -= self.learning_rate * grad_b\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.m) + self.b\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        y_pred = self.predict(X_test)\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        return {\"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n"
      ],
      "metadata": {
        "id": "ixJKdAZb6cWs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_gd = RidgeRegressionGradientDescent(alpha=1.0, learning_rate=0.1, epochs=1000)\n",
        "ridge_gd.fit(x_train, y_train)\n",
        "print(\"Gradient Descent Metrics:\", ridge_gd.evaluate(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKl9gsYD6iPd",
        "outputId": "2cea10f7-ce12-4448-aacf-bc8cd66a94ea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Descent Metrics: {'MSE': 23203490.81380512, 'RMSE': 4817.000188271236, 'R2': 0.8311441989896226}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation using the sklearn"
      ],
      "metadata": {
        "id": "h4BcBaxs8HRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "class RidgeRegressionSklearn:\n",
        "    def __init__(self, alpha=1.0):\n",
        "        \"\"\"\n",
        "        Ridge Regression using Scikit-Learn.\n",
        "        :param alpha: Regularization strength (lambda).\n",
        "        \"\"\"\n",
        "        self.alpha = alpha\n",
        "        self.model = Ridge(alpha=self.alpha)\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Train the Ridge Regression model.\n",
        "        :param X_train: Training feature matrix.\n",
        "        :param y_train: Training target vector.\n",
        "        \"\"\"\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"\n",
        "        Make predictions on test data.\n",
        "        :param X_test: Test feature matrix.\n",
        "        :return: Predicted values.\n",
        "        \"\"\"\n",
        "        return self.model.predict(X_test)\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Evaluate the model using regression metrics.\n",
        "        :param X_test: Test feature matrix.\n",
        "        :param y_test: Actual target values.\n",
        "        :return: Dictionary containing MSE, MAE, and RÂ² score.\n",
        "        \"\"\"\n",
        "        y_pred = self.predict(X_test)\n",
        "        metrics = {\n",
        "            \"MSE\": mean_squared_error(y_test, y_pred),\n",
        "            \"MAE\": mean_absolute_error(y_test, y_pred),\n",
        "            \"R2 Score\": r2_score(y_test, y_pred)\n",
        "        }\n",
        "        return metrics\n"
      ],
      "metadata": {
        "id": "gyDzTT7x6wsl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_sklearn = RidgeRegressionSklearn(alpha=1.0)\n",
        "ridge_sklearn.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "metrics = ridge_sklearn.evaluate(x_test, y_test)\n",
        "print(\"Sklearn Ridge Regression Metrics:\", metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WUEkGY88QXo",
        "outputId": "ecaf016a-b26f-4ec4-80cf-47b7e5c0086f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn Ridge Regression Metrics: {'MSE': 15151108.707749903, 'MAE': 2646.6380124665143, 'R2 Score': 0.8897427711385435}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_f6-bOa58X6x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}